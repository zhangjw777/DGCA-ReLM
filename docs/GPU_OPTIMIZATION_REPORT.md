# GPUæ€§èƒ½ä¼˜åŒ–æŠ¥å‘Š

**æ—¥æœŸ**: 2025å¹´12æœˆ21æ—¥  
**é¡¹ç›®**: DGCA-ReLM  
**é—®é¢˜**: è®­ç»ƒæ—¶GPUåˆ©ç”¨ç‡ä½ï¼ŒåŠŸç‡åªæœ‰200Wï¼ˆæ»¡è½½450Wï¼‰

---

## ğŸ“Š è¯Šæ–­æµ‹è¯•æ•°æ®

ä½¿ç”¨ `diagnose_gpu.py` è¿›è¡Œåˆ†æ­¥æµ‹è¯•ï¼ˆbatch_size=128, seq_len=128ï¼‰ï¼š

| æµ‹è¯•é¡¹ | é€Ÿåº¦ | ååé‡ | GPUåŠŸç‡ | è¯´æ˜ |
|--------|------|--------|---------|------|
| æµ‹è¯•1: çº¯BERTæ¨ç† | 111.6ms/iter | 1147 samples/s | **400W+** | GPUæ»¡è½½ |
| æµ‹è¯•2: BERTè®­ç»ƒ | 335.3ms/iter | 381.7 samples/s | **400W+** | GPUæ»¡è½½ |
| æµ‹è¯•3: BERT+FP16 | 162.9ms/iter | 785.5 samples/s | 350W | FP16å‡å°‘è®¡ç®— |
| æµ‹è¯•4: DataLoader | 12.4ms/batch | - | N/A | æ•°æ®åŠ è½½å¾ˆå¿« |
| æµ‹è¯•5: çœŸå®æ•°æ®+BERT | 186.4ms/iter | 686.7 samples/s | 350W | ç•¥æœ‰ä¸‹é™ |
| æµ‹è¯•6: å®Œæ•´DGCAæ¨¡å‹ | 579.4ms/iter | 220.9 samples/s | **200W** | âš ï¸ GPUç­‰å¾… |

**å…³é”®å‘ç°**: æµ‹è¯•6(DGCA)æ¯”æµ‹è¯•3(BERT+FP16)æ…¢äº†3.5å€ï¼ŒåŠŸç‡ä½äº†150W

---

## ğŸ” ç“¶é¢ˆåˆ†æ

### 1. å·²æ’é™¤çš„å› ç´ 

- âŒ **æ•°æ®åŠ è½½ç“¶é¢ˆ**: æµ‹è¯•4æ˜¾ç¤ºDataLoaderé€Ÿåº¦å¾ˆå¿«(12.4ms/batch)
- âŒ **mmap I/Oé—®é¢˜**: ä½¿ç”¨`--preload_data`é¢„åŠ è½½åˆ°å†…å­˜åé€Ÿåº¦æ— å˜åŒ–
- âŒ **num_workersç«äº‰**: num_workers=2/4/8é€Ÿåº¦ç›¸åŒ

### 2. æ‰¾åˆ°çš„çœŸæ­£ç“¶é¢ˆ

#### âš ï¸ æ ¸å¿ƒé—®é¢˜: `_apply_prompt`ä¸­çš„åŒé‡Python forå¾ªç¯

```python
# åŸå§‹ä»£ç  - æ¯æ¬¡forwardæ‰§è¡Œ768æ¬¡Pythonå¾ªç¯ï¼
for i in range(batch_size):           # 128æ¬¡
    for j in range(2 * self.prompt_length):  # 6æ¬¡
        inputs_embeds[i, blocked_indices[i, j], :] = replace_embeds[j, :]
```

**é—®é¢˜æ ¹æº**: 
- æ¯æ¬¡å¾ªç¯éƒ½æ˜¯ä¸€æ¬¡CUDA kernel launch
- Pythonå¾ªç¯å¼€é”€ + CUDA kernelå¯åŠ¨å¼€é”€å åŠ 
- batch_size=128æ—¶ï¼Œæ¯ä¸ªforwardè¦768æ¬¡kernel launch

---

## âœ… å·²å®Œæˆçš„ä¼˜åŒ–

### ä¼˜åŒ–1: `_apply_prompt` å‘é‡åŒ–ï¼ˆæœ€å…³é”®ï¼ï¼‰

**æ–‡ä»¶**: `multiTask/DGCAModel.py`

```python
# ä¼˜åŒ–å - å•æ¬¡å‘é‡åŒ–æ“ä½œ
prompt_positions = (prompt_mask[0] == 1).nonzero(as_tuple=True)[0]
replace_embeds_expanded = replace_embeds.unsqueeze(0).expand(batch_size, -1, -1)
inputs_embeds.index_copy_(1, prompt_positions, replace_embeds_expanded)
```

### ä¼˜åŒ–2: `dynamic_mask_token` GPUåŒ–

**æ–‡ä»¶**: `run_dgca_relm.py`

- ç§»é™¤`tokenizer.get_special_tokens_mask()`çš„CPUè°ƒç”¨
- å…¨éƒ¨ä½¿ç”¨GPUä¸Šçš„å‘é‡åŒ–æ“ä½œ

### ä¼˜åŒ–3: `GatedFusion` å†…å­˜ä¼˜åŒ–

**æ–‡ä»¶**: `multiTask/DGCAModel.py`

- ä½¿ç”¨`scatter_add_`åŸåœ°æ“ä½œæ›¿ä»£åˆ›å»ºvocab_sizeå¤§å°çš„é›¶å¼ é‡
- å‡å°‘çº¦1.3GBä¸´æ—¶å†…å­˜åˆ†é…

### ä¼˜åŒ–4: `PreprocessedDataset` ä¼˜åŒ–

**æ–‡ä»¶**: `utils/dgca_data_processor.py`

- `clone()` -> `contiguous()`å‡å°‘ä¸å¿…è¦æ‹·è´
- æ–°å¢`preload_to_memory`é€‰é¡¹

### ä¼˜åŒ–5: DataLoaderé…ç½®

**æ–‡ä»¶**: `run_dgca_relm.py`

- æ–°å¢`--preload_data`å‚æ•°
- æ–°å¢`--prefetch_factor`å‚æ•°
- æ·»åŠ `drop_last=True`

---

## ğŸ“ˆ ä¼˜åŒ–æ•ˆæœ

| æŒ‡æ ‡ | ä¼˜åŒ–å‰ | ä¼˜åŒ–å | æå‡ |
|------|--------|--------|------|
| è®­ç»ƒé€Ÿåº¦ | 2.2 it/s | **4.9 it/s** | **2.2x** |
| GPUåŠŸç‡ | 200W | **320W** | +60% |
| åˆ©ç”¨ç‡ä¼°ç®— | ~44% | ~71% | +27% |

---

## ğŸ”® å¾…ç»§ç»­ä¼˜åŒ–çš„é—®é¢˜

### 1. åŒå¡DDPè®­ç»ƒåè€Œæ›´æ…¢

**ç°è±¡**: 
- å•å¡: 2.2 it/s (ä¼˜åŒ–å‰) / 4.9 it/s (ä¼˜åŒ–å)
- åŒå¡: 1.5 it/sï¼Œæ¯å¡åŠŸç‡åªæœ‰100W

**å¯èƒ½åŸå› **:
- NCCLé€šä¿¡å¼€é”€
- æ¢¯åº¦åŒæ­¥ç“¶é¢ˆ
- batch_size=128åœ¨åŒå¡ä¸‹æ¯å¡åªæœ‰64ï¼Œè®¡ç®—æ•ˆç‡ä¸‹é™

**å¾…æµ‹è¯•**:
- åŒå¡æ—¶å¢å¤§batch_sizeåˆ°256æˆ–æ›´é«˜
- æ£€æŸ¥gradient_accumulation_stepsè®¾ç½®
- ä½¿ç”¨`torch.distributed.barrier()`å®šä½åŒæ­¥å¼€é”€

### 2. åŠŸç‡ä»æœªæ»¡è½½ï¼ˆ320W vs 450Wï¼‰

**å¯èƒ½åŸå› **:
- DetectorHeadã€CandidateHeadé¢å¤–è®¡ç®—å¼€é”€
- æ··åˆç²¾åº¦ä¸‹æŸäº›æ“ä½œfallbackåˆ°FP32
- å†…å­˜å¸¦å®½ç“¶é¢ˆï¼ˆcandidate_embeddings lookupï¼‰

**å¾…åˆ†æ**:
- ä½¿ç”¨`torch.profiler`è¯¦ç»†åˆ†æå„æ“ä½œè€—æ—¶
- æ£€æŸ¥æ˜¯å¦æœ‰CUDAåŒæ­¥ç‚¹å¯¼è‡´çš„ç­‰å¾…

### 3. diagnose_gpu.py æµ‹è¯•6 å¾…æ›´æ–°

éœ€è¦æ›´æ–°æµ‹è¯•6ä½¿ç”¨ä¼˜åŒ–åçš„ä»£ç é‡æ–°æµ‹è¯•åŸºå‡†ã€‚

---

## ğŸ“ é…ç½®å»ºè®®

### å½“å‰æ¨èé…ç½®ï¼ˆå•å¡4090ï¼‰

```bash
CUDA_VISIBLE_DEVICES=1 python run_dgca_relm.py \
    --do_train --do_eval --do_test \
    --preprocessed_train data/train.pt \
    --preprocessed_eval data/dev.pt \
    --preprocessed_test data/test.pt \
    --fp16 --apply_prompt --mft \
    --train_batch_size 128 \
    --num_workers 4 \
    --prefetch_factor 2
```

### å¾…éªŒè¯é…ç½®ï¼ˆåŒå¡ï¼‰

```bash
torchrun --nproc_per_node=2 --master_port=29500 run_dgca_relm.py \
    --do_train --do_eval --do_test \
    --preprocessed_train data/train.pt \
    --preprocessed_eval data/dev.pt \
    --preprocessed_test data/test.pt \
    --fp16 --apply_prompt --mft \
    --train_batch_size 256 \
    --gradient_accumulation_steps 1 \
    --num_workers 4
```

---

## ğŸ› ï¸ ä¸‹æ¬¡ç»§ç»­çš„æ–¹å‘

1. **åŒå¡è®­ç»ƒä¼˜åŒ–**: åˆ†æDDPé€šä¿¡å¼€é”€ï¼Œå°è¯•gradient_accumulation
2. **è¿›ä¸€æ­¥æå‡å•å¡åˆ©ç”¨ç‡**: ä½¿ç”¨torch.profileræ‰¾å‡ºå‰©ä½™ç“¶é¢ˆ
3. **ç¼–è¯‘ä¼˜åŒ–**: å°è¯•`torch.compile()`ï¼ˆPyTorch 2.0+ï¼‰
4. **æ›´å¤§batch_size**: æµ‹è¯•batch_size=192/256çš„æ•ˆæœ
